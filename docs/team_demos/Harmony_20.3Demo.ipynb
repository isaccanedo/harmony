{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmony and STAC: PI 20.3 Demo\n",
    "\n",
    "In PI 20.3, Harmony updated their service integrator's guide with improved guidance on transformation metadata to include in backend service outputs. In addition, we helped to ensure that the Harmony STAC catalog contains accurate spatial and temporal metadata representing the subsetted outputs produced by each backend service. \n",
    "\n",
    "This notebook provides a basic workflow to access Harmony outputs in-place from the s3 locations provided by the STAC catalog generated from an asynchronous request. For more a general introduction and tutorial, see [Harmony API Introduction](./Harmony%20Api%20Introduction.ipynb).  Useful helpers for making the calls found in this notebook can be found under the [docs/notebook-helpers](./notebook-helpers) folder.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "#### You must run this notebook within an EC2 instance running in us-west-2:\n",
    "1. Follow tutorials 01 through 03 of the [NASA Earthdata Cloud Primer](https://earthdata.nasa.gov/learn/user-resources/webinars-and-tutorials/cloud-primer) to set up an EC2 instance within us-west-2. Ensure you are also following step 3 in the [\"Jupyter Notebooks on AWS EC2 in 12 (mostly easy) steps\"](https://medium.com/@alexjsanchez/python-3-notebooks-on-aws-ec2-in-15-mostly-easy-steps-2ec5e662c6c6) article to set the correct security group settings needed to connect your local port to your EC2â€™s notebook port thru SSH.\n",
    "\n",
    "2. Follow the remaining instructions in the Medium article above, which includes installation of Anaconda3 (including Jupyter Lab) in your ec2 instance. Before moving over to Jupyter Lab, perform steps 3 - 4 to set up Earthdata Login and Harmony access:\n",
    "\n",
    "3. Setup your `~/.netrc` for Earthdata Login in your ec2 instance:\n",
    "\n",
    "`machine uat.urs.earthdata.nasa.gov login <user> password <password>`\n",
    "\n",
    "4. Run the following in your ec2 instance terminal window to generate short-term Harmony access keys:\n",
    "\n",
    "`curl -Ln -bj https://harmony.uat.earthdata.nasa.gov/cloud-access.sh`\n",
    "\n",
    "5. Set your environment variables based on the keys provided in step 4:\n",
    "\n",
    "`export AWS_ACCESS_KEY_ID='...\n",
    "export AWS_SECRET_ACCESS_KEY='...'\n",
    "export AWS_SESSION_TOKEN='...'\n",
    "export AWS_DEFAULT_REGION='us-west-2'`\n",
    "\n",
    "6. Once the notebook is running in Jupyter Lab, run the following cell to install Python dependencies, import necessary modules, and set notebook defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import sys\n",
    "# Install dependencies into the Jupyter Kernel\n",
    "!{sys.executable} -m pip install -q -r ../notebook_helpers/requirements.txt\n",
    "!{sys.executable} -m pip install intake-stac\n",
    "%matplotlib inline\n",
    "\n",
    "# Import libraries used throughout the notebook\n",
    "from notebook_helpers import get, post, show, get_data_urls, show_async, show_async_condensed, print_async_status, show_shape\n",
    "import json\n",
    "import intake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASF Data Transformations\n",
    "\n",
    "The ASF gdal service provides subsetting, reformatting, and reprojection capabilities for ASF's Sentinel-1 Interferograms (BETA) product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_collection = 'C1225776654-ASF'\n",
    "coverages_root = 'https://harmony.uat.earthdata.nasa.gov/{collection}/ogc-api-coverages/1.0.0/collections/{variable}/coverage/rangeset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable and spatial subsetting with projecting, reformtatting output to PNG and spatial constraints\n",
    "Each parent NetCDF is approx. 60 MB and the subsetted pngs and geotiffs are well under 1 MB each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = get(\n",
    "    coverages_root.format(\n",
    "        collection=asf_collection, \n",
    "        variable='science%2Fgrids%2Fdata%2Fcoherence'),\n",
    "    params={\n",
    "        'format': 'image/png',\n",
    "        'outputcrs': 'EPSG:2230',\n",
    "        'subset': [\n",
    "            'lon(-115.5:-115.25)', \n",
    "            'lat(33:33.1)',\n",
    "            'time(\"2020-03-13T00:00:00Z\":\"2020-03-13T23:59:59Z\")'\n",
    "            ]})\n",
    "\n",
    "show_async(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the STAC response using `intake-stac`\n",
    "\n",
    "Each asynchronous request response includes a [STAC](https://stacspec.org/) catalog that contains spatial and temporal metadata for each output, or STAC item. These metadata fields now reflect the values of the subsetted outputs themselves, providing transformation metadata for users. The [Pangeo gallery](http://gallery.pangeo.io/repos/pangeo-data/pangeo-tutorial-gallery/intake.html) includes great guidance on how to work with stac catalogs to access cloud-hosted data in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store job ID to create STAC location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.loads(response.content)\n",
    "job = results['jobID']\n",
    "print(job)\n",
    "\n",
    "stac_root = 'https://harmony.uat.earthdata.nasa.gov/stac/{jobID}/{item}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open STAC Catalog from Harmony async response\n",
    "\n",
    "Two STAC items are listed, corresponding to the two outputs plotted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_cat = intake.open_stac_catalog(stac_root.format(jobID=job,item=''),name='Harmony output')\n",
    "display(list(stac_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stac_cat)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the metadata of each STAC item, which includes the bounding box, coordinates, and start and end time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list(stac_cat))):\n",
    "    display(intake.open_stac_item(stac_root.format(jobID=job,item=i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item can be accessed from the harmony s3 staging bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for id, entry in stac_cat.search('type').items():\n",
    "    display(entry)\n",
    "    entries.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Harmony outputs directly from STAC \n",
    "\n",
    "The Harmony output image is loaded up into an xarray data array directly from the STAC catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = stac_cat[list(stac_cat)[0]][entries[0].describe()['name']].to_dask()\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to non subsetted granule\n",
    "\n",
    "The STAC metadata reflect the native granule bounds for an equivalent request without spatial subsetting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_nosubset = get(\n",
    "    coverages_root.format(\n",
    "        collection=asf_collection, \n",
    "        variable='science%2Fgrids%2Fdata%2Fcoherence'),\n",
    "    params={\n",
    "        'format': 'image/png',\n",
    "        'granuleID': 'G1234646236-ASF',\n",
    "        'outputcrs': 'EPSG:2230',\n",
    "        'forceAsync' : 'true',\n",
    "        'subset': [\n",
    "            'time(\"2020-03-13T00:00:00Z\":\"2020-03-13T23:59:59Z\")'\n",
    "            ]})\n",
    "show_async_condensed(response_nosubset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nosubset = json.loads(response_nosubset.content)\n",
    "job_nosubset = results_nosubset['jobID']\n",
    "\n",
    "stac_cat_nosubset = intake.open_stac_catalog(stac_root.format(jobID=job_nosubset,item=''),name='Harmony output')\n",
    "\n",
    "display(intake.open_stac_item(stac_root.format(jobID=job_nosubset,item='0')))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
