{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nasa/harmony/blob/main/docs/Harmony%20API%20introduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmony API Introduction\n",
    "\n",
    "This notebook provides an overview of the capabilities offered through the Harmony API, which supports the [OpenGIS Web Map Service](https://www.ogc.org/standards/wms#overview) and the [OGC API - Coverages](https://github.com/opengeospatial/ogc_api_coverage) specification. The examples below demonstrate synchronous and asynchronous access of several subsetting and reprojection services available from the Harmony/gdal demo service, native data access for data without transformation services, and the WMS map image service. \n",
    "\n",
    "Authors: Amy Steiker, Patrick Quinn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "Most packages below should be included natively with the Anaconda Python distribution, for example, but some may need to install packages like `rasterio` manually using the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install prerequisite packages\n",
    "import sys\n",
    "\n",
    "# Note you usually need to install gdal outside of Python / pip first. On OSX, brew install gdal\n",
    "!{sys.executable} -m pip install rasterio OWSLib GDAL matplotlib netCDF4 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request, parse\n",
    "from http.cookiejar import CookieJar\n",
    "from base64 import b64encode\n",
    "import getpass\n",
    "import netrc\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import time\n",
    "from netCDF4 import Dataset\n",
    "from owslib.wms import WebMapService\n",
    "from owslib.util import Authentication\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local directory setup \n",
    "\n",
    "Specify a local directory where the following Harmony outputs will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = './outputs/'\n",
    "if not os.path.exists(local_dir):\n",
    "  os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earthdata Login Authentication\n",
    "\n",
    "An Earthdata Login account is required to access data from NASA EOSDIS. In order to access data from the Harmony API, you will need to create an account in the Earthdata Login UAT environment. Please visit https://uat.urs.earthdata.nasa.gov to set up an account in this test environment. These accounts, as all Earthdata Login accounts, are free to create and only take a moment to set up.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some boilerplate up front to log in to Earthdata Login.  The function below will allow Python scripts to log into any Earthdata Login application programmatically.  To avoid being prompted for\n",
    "credentials every time you run and also allow clients such as curl to log in, you can add the following\n",
    "to a `.netrc` (`_netrc` on Windows) file in your home directory:\n",
    "\n",
    "```\n",
    "machine uat.urs.earthdata.nasa.gov\n",
    "    login <your username>\n",
    "    password <your password>\n",
    "```\n",
    "\n",
    "Make sure that this file is only readable by the current user or you will receive an error stating\n",
    "\"netrc access too permissive.\"\n",
    "\n",
    "`$ chmod 0600 ~/.netrc` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_earthdata_login_auth(endpoint):\n",
    "    \"\"\"\n",
    "    Set up the request library so that it authenticates against the given Earthdata Login\n",
    "    endpoint and is able to track cookies between requests.  This looks in the .netrc file \n",
    "    first and if no credentials are found, it prompts for them.\n",
    "\n",
    "    Valid endpoints include:\n",
    "        uat.urs.earthdata.nasa.gov - Earthdata Login UAT (Harmony's current default)\n",
    "        urs.earthdata.nasa.gov - Earthdata Login production\n",
    "    \"\"\"\n",
    "    token = None\n",
    "    try:\n",
    "        username, _, password = netrc.netrc().authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        # FileNotFound = There's no .netrc file\n",
    "        # TypeError = The endpoint isn't in the netrc file, causing the above to try unpacking None\n",
    "        print('Please provide your Earthdata Login credentials to allow data access')\n",
    "        print('Your credentials will only be passed to %s and will not be exposed in Jupyter' % (endpoint))\n",
    "        username = input('Username:')\n",
    "        print('Password:')\n",
    "        password = getpass.getpass()\n",
    "        \n",
    "        # Retrieve existing bearer token or generate a new one if none exists\n",
    "        basic_auth_string = f'{username}:{password}'\n",
    "        basic_auth_bytes = basic_auth_string.encode('ascii')\n",
    "        base64_bytes = b64encode(basic_auth_bytes)\n",
    "        base64_basic_auth = base64_bytes.decode('ascii')\n",
    "        try:\n",
    "            token_response = requests.get(f'https://{endpoint}/api/users/tokens', headers={'Authorization': f'Basic {base64_basic_auth}'})\n",
    "            token_response_json = token_response.json()\n",
    "            if token_response_json:\n",
    "                token = token_response_json[0]['access_token']\n",
    "            else: \n",
    "                token_response = requests.post(f'https://{endpoint}/api/users/token', headers={'Authorization': f'Basic {base64_basic_auth}'})\n",
    "                token_response_json = token_response.json()\n",
    "                token = token_response_json['access_token']\n",
    "        except:\n",
    "            print(f'Error: token response: {token_response_json}')\n",
    "\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)\n",
    "    return token\n",
    "\n",
    "class BearerToken(requests.auth.AuthBase):\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "    def __call__(self, r):\n",
    "        r.headers['Authorization'] = f'Bearer {self.token}'\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the above function to set up Earthdata Login for subsequent requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = setup_earthdata_login_auth('uat.urs.earthdata.nasa.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify a data collection of interest\n",
    "\n",
    "A CMR collection ID is needed to request services through Harmony. The collection ID can be determined using the [CMR API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html). We will query the corresponding ID of a known collection short name, `harmony_example`, which is a Level 3 test collection with transformation services available through Harmony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'short_name': 'harmony_example',\n",
    "    'version': 2\n",
    "} # parameter dictionary with known CMR short_name and version\n",
    "\n",
    "cmr_collections_url = 'https://cmr.uat.earthdata.nasa.gov/search/collections.json'\n",
    "query_string = parse.urlencode(params) \n",
    "url = cmr_collections_url + \"?\" + query_string \n",
    "cmr_response = request.urlopen(url)\n",
    "cmr_results = json.loads(cmr_response.read().decode('utf-8'))\n",
    "\n",
    "collectionlist = [el['id'] for el in cmr_results['feed']['entry']]\n",
    "harmony_collection_id = collectionlist[0]\n",
    "print(harmony_collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the `harmony_example` collection metadata to glean more information about the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint.pprint(cmr_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine service availability\n",
    "\n",
    "We will determine what services are available for the `harmony_example` collection based on the Harmony capabilities endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "capabilities_url = f'https://harmony.uat.earthdata.nasa.gov/capabilities?collectionId={harmony_collection_id}'\n",
    "r = requests.get(capabilities_url)\n",
    "r.json()['services']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the services.yml, our `harmony_example` collection is associated with the `harmony/gdal` service with bounding box and variable subsetting, reprojection, and reformatting. We will request these services below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Harmony Root URL\n",
    "\n",
    "Harmony conforms to the OGC API - Coverages specification: https://github.com/opengeospatial/ogc_api_coverages.\n",
    "\n",
    "The basic Harmony URL convention is as follows:\n",
    "\n",
    "`<harmony_root>/<collection_id>/ogc-api-coverages/1.0.0/`\n",
    "\n",
    "We will set the Harmony root path with our chosen collection id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "harmony_root = 'https://harmony.uat.earthdata.nasa.gov'\n",
    "config = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0'\n",
    "}\n",
    "coverages_root = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/'.format(**config)\n",
    "print('Request URL', coverages_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This root URL of the coverages endpoint provides links to its child resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_response = request.urlopen(coverages_root)\n",
    "root_results = root_response.read()\n",
    "root_json = json.loads(root_results.decode('utf-8'))\n",
    "pprint.pprint(root_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `service_desc` endpoint contains OpenAPI documentation, including information on all supported request parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "service_desc = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/api/'.format(**config)\n",
    "service_response = request.urlopen(service_desc)\n",
    "service_results = service_response.read()\n",
    "service_txt = service_results.decode('utf-8') \n",
    "print(service_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `conformance` endpoint provides the specifications this API conforms to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conform_desc = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/conformance/'.format(**config)\n",
    "conform_response = request.urlopen(conform_desc)\n",
    "conform_results = conform_response.read()\n",
    "conform_json = json.loads(conform_results.decode('utf-8'))\n",
    "print(conform_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `collections` endpoint provides metadata on the resource collections, which include variable metadata from CMR's [UMM-Var schema](https://git.earthdata.nasa.gov/projects/EMFD/repos/unified-metadata-model/browse/variable) in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "collections_desc = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/'.format(**config)\n",
    "collections_response = request.urlopen(collections_desc)\n",
    "collections_results = collections_response.read()\n",
    "collections_json = json.loads(collections_results.decode('utf-8'))\n",
    "pprint.pprint(collections_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access native data without transformation services"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For EOSDIS collections without associated Harmony transformation services, the Harmony API can still be utilized to access data through the provided data access links. Before we request services for `harmony_example`, We will use `MYD13Q1`, or the \"MODIS/Aqua Vegetation Indices 16-Day L3 Global 250m SIN Grid V061\" data product, as an example of this \"no processing\" request. \n",
    "\n",
    "The URL for requesting `MYD13Q1` is printed below. In this simple case, the entire data product is requested. The request response is also printed below, which includes information such as JobID, data access links, associated granule IDs, request messages, and status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "noProcConfig = {\n",
    "    'is2collection_id': 'C1256583785-EEDTEST',\n",
    "    'ogc-api-coverages_version': '1.0.0'\n",
    "}\n",
    "\n",
    "no_proc_url = harmony_root+'/{is2collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/all/coverage/rangeset'.format(**noProcConfig)\n",
    "print('Request URL', no_proc_url)\n",
    "\n",
    "no_proc_response = request.urlopen(no_proc_url)\n",
    "no_proc_results = no_proc_response.read()\n",
    "no_proc_json = json.loads(no_proc_results)\n",
    "pprint.pprint(no_proc_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the request located all granules available in that collection.  We can pull those data access links from the request response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links = no_proc_json['links'] #list of links from response\n",
    "\n",
    "for i in range(len(links)):\n",
    "    link_dict = links[i] \n",
    "    print(link_dict['href'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of requesting the entire `MYD13Q1` collection, we can also specify a single granule ID to download. For convenience, the first granule returned in the request above is queried separately to demonstrate this single granule request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine first granule ID in list\n",
    "first_link_dict = links[0] \n",
    "granuleID = first_link_dict['title']\n",
    "print(granuleID)\n",
    "\n",
    "# Update noProcConfig\n",
    "noProcConfig = {\n",
    "    'is2collection_id': 'C1256583785-EEDTEST',\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'granuleID': granuleID\n",
    "}\n",
    "\n",
    "no_proc_single_url = harmony_root+'/{is2collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?granuleID={granuleID}'.format(**noProcConfig)\n",
    "print(no_proc_single_url)\n",
    "no_proc_single_response = request.urlopen(no_proc_single_url)\n",
    "no_proc_single_results = no_proc_single_response.read()\n",
    "no_proc_single_json = json.loads(no_proc_single_results)\n",
    "pprint.pprint(no_proc_single_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single file output is downloaded to a directory with write permissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_link = no_proc_single_json['links']\n",
    "single_dict = single_link[0]\n",
    "file_url = single_dict['href']\n",
    "\n",
    "file_response = request.urlopen(file_url)\n",
    "file_results = file_response.read()\n",
    "\n",
    "# Write data to file \n",
    "file_name = 'harmonyNoProc.h5'\n",
    "filepath = str(local_dir+file_name)\n",
    "file_ = open(filepath, 'wb')\n",
    "file_.write(file_results)\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data subsetted by variable\n",
    "\n",
    "Now we'll move into some subsetting examples with the `harmony_example` collection, beginning with a basic variable subset of a single pre-determined granule with global coverage. The variable request is included in the URL below as a /collections path. As stated in the API documentation, \"This API interprets OGC 'collections' to be equivalent to CMR 'variables'\". Unlike the no processing requests above, this result will be returned synchronously to us. By default, any single granule request that has associated Harmony services will be returned synchronously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "granule_id = 'G1234088196-EEDTEST'\n",
    "varSubsetConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'blue_var',\n",
    "    'granuleid': granule_id\n",
    "}\n",
    "var_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?granuleid={granuleid}'.format(**varSubsetConfig)\n",
    "print('Request URL', var_url)\n",
    "var_response = request.urlopen(var_url)\n",
    "var_results = var_response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single subsetted file output is downloaded to the Harmony outputs directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'harmonyvarsubset.tif'\n",
    "var_filepath = str(local_dir+file_name)\n",
    "file_ = open(var_filepath, 'wb')\n",
    "file_.write(var_results)\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the TIF output of the single `blue_var` band to verify our output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_raster = rasterio.open(var_filepath)\n",
    "blue = var_raster.read(1) # read first band, in this case blue_var\n",
    "plt.imshow(blue, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data subsetted by geographic bounding box\n",
    "\n",
    "Using the same global coverage granule as above, we will request a bounding box subset over Australia. Harmony supports spatial subset requests within the `rangeset` query in the following structure: \n",
    "\n",
    "`subset=lat(South:North)&subset=lon(West:East)`\n",
    "\n",
    "More details included in the Harmony documentation:\n",
    "\n",
    "Harmony supports the axes \"lat\" and \"lon\" for spatial subsetting, regardless of the names of those axes in the data files.  Examples:\n",
    "- Subset to the lat/lon bounding box with southwest corner (-10, -10) and northeast corner (10, 10)\n",
    "            subset=lat(-10:10)&subset=lon(-10:10)\n",
    "- Subset to all latitudes north of -10 degrees and all longitudes west of 10 degrees\n",
    "            subset=lat(-10:*)&subset=lon(*:10)\n",
    "- Subset to only points with latitudes from -10 to 10 degrees, disregarding longitude\n",
    "            subset=lat(-10:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bboxSubsetConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'granuleid': granule_id,\n",
    "    'lat': '(-45.75:-9)',\n",
    "    'lon': '(110:156)'\n",
    "}\n",
    "bbox_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?granuleid={granuleid}&subset=lat{lat}&subset=lon{lon}'.format(**bboxSubsetConfig)\n",
    "print('Request URL', bbox_url)\n",
    "bbox_response = request.urlopen(bbox_url)\n",
    "bbox_results = bbox_response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This spatially subsetted file output is downloaded to the Harmony outputs directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_file_name = 'harmonybboxsubset.tif'\n",
    "bbox_filepath = str(local_dir+bbox_file_name)\n",
    "file_ = open(bbox_filepath, 'wb')\n",
    "file_.write(bbox_results)\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the TIF output of the subsetted file to verify our output. All bands are overlaid to plot the color composite, with this code example modified from the following source:\n",
    "\n",
    "https://automating-gis-processes.github.io/CSC/notebooks/L5/plotting-raster.html \\\n",
    "© Copyright 2018, Henrikki Tenkanen \\\n",
    "[License](https://creativecommons.org/licenses/by-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file:\n",
    "bbox_raster = rasterio.open(bbox_filepath)\n",
    "\n",
    "# Read the grid values into numpy arrays\n",
    "red = bbox_raster.read(3)\n",
    "green = bbox_raster.read(2)\n",
    "blue = bbox_raster.read(1)\n",
    "\n",
    "# Function to normalize the grid values\n",
    "def normalize(array):\n",
    "    \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\"\n",
    "    import numpy as np\n",
    "    np.seterr(divide='ignore', invalid='ignore') #ignore divide by 0 error\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    return ((array - array_min)/(array_max - array_min))\n",
    "\n",
    "# Normalize the bands\n",
    "redn = normalize(red)\n",
    "greenn = normalize(green)\n",
    "bluen = normalize(blue)\n",
    "\n",
    "# Create RGB natural color composite\n",
    "rgb = np.dstack((redn, greenn, bluen))\n",
    "\n",
    "# Let's see how our color composite looks like\n",
    "plt.imshow(rgb);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data filtered by temporal range\n",
    "\n",
    "Filtering data results by temporal range is also available on this test collection. According to the Harmony API documentation, the `time` keyword within the `rangeset` query supports the following:\n",
    "\n",
    "Either a date-time or a period string that adheres to RFC 3339. Examples:\n",
    "        * A date-time: \"2018-02-12T23:20:50Z\" * A period: \"2018-02-12T00:00:00Z/2018-03-18T12:31:12Z\" or \"2018-02-12T00:00:00Z/P1M6DT12H31M12S\"\n",
    "Only collections that have a temporal property that intersects the value of `time` are selected. If a collection has multiple temporal properties, it is the decision of the server whether only a single temporal property is used to determine the extent or all relevant temporal properties.\n",
    "\n",
    "We will search for the following time range:\n",
    "\n",
    "Start time: 2020-02-16 02:00:00 \\\n",
    "End time: 2020-02-16 03:00:00\n",
    "\n",
    "According to [Earthdata Search](https://search.uat.earthdata.nasa.gov/search/granules?p=C1234088182-EEDTEST&pg[0][v]=f&pg[0][gsk]=-start_date&q=harmony_example&qt=2020-02-16T02%3A00%3A00.000Z%2C2020-02-16T03%3A00%3A00.000Z&tl=1567098728!4!!&lat=-66.80545903827544&long=19.313018908611213&zoom=1), a single granule `2020_02_16_ff0000_africa` is returned over this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeSubsetConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'time': '(\"2020-02-16T02:00:00.000Z\":\"2020-02-16T03:00:00.000Z\")'\n",
    "}\n",
    "\n",
    "time_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?&subset=time{time}'.format(**timeSubsetConfig)\n",
    "print('Request URL', time_url)\n",
    "time_response = request.urlopen(time_url)\n",
    "time_results = time_response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file returned over the time range of interest is downloaded to the Harmony outputs directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_file_name = 'harmonytimesubset.tif'\n",
    "time_filepath = str(local_dir+time_file_name)\n",
    "file_ = open(time_filepath, 'wb')\n",
    "file_.write(time_results)\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the TIF output of this file to verify the coverage over Africa (for simplicity, plotting the first band):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_raster = rasterio.open(time_filepath)\n",
    "time_band = time_raster.read(1)\n",
    "plt.imshow(time_band, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data subsetted by geographic shapefile\n",
    "We will request data overlapping South America by uploading a shapefile with that boundary.\n",
    "\n",
    "This requires the use of a multipart/form-data POST request. Supported shapefile formats include ESRI, GeoJSON, and KML. The associated mime-types are as follows:\n",
    "\n",
    "| Shapefile Format | mime-type |\n",
    "|:-----------------|----------:|\n",
    "| ESRI | application/shapefile+zip |\n",
    "| GeoJSON | application/geo+json |\n",
    "| KML | application/vnd.google-earth.kml+xml |\n",
    "\n",
    "\n",
    "ESRI shapefiles must be uploaded as a single .zip file.\n",
    "See the Harmony documenation for more details.\n",
    "\n",
    "Note that this request is using the shapefile for the search that it is performing to find data. It will also be used for shapefile subsetting if the service that this request is routed to supports it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefileSubsetConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'blue_var,red_var,green_var',\n",
    "    'format': 'image/tiff'\n",
    "}\n",
    "\n",
    "shapefile_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?format={format}'.format(**shapefileSubsetConfig)\n",
    "# download the shapefile from github\n",
    "shapefile_github_raw_url = 'https://raw.githubusercontent.com/nasa/harmony/main/docs/shapefiles/south_america.geojson'\n",
    "shapefile_path = local_dir+'./south_america.geojson'\n",
    "r = requests.get(shapefile_github_raw_url, stream=True)\n",
    "with open(shapefile_path, 'wb') as fd:\n",
    "    for chunk in r.iter_content(chunk_size=128):\n",
    "        fd.write(chunk)\n",
    "\n",
    "with open(shapefile_path, 'rb') as fd1:\n",
    "    # the form must have a 'shapefile' key which must include the mime-type as shown. Additional parameters\n",
    "    # such as temporal subsetting can be included in the form.\n",
    "    multipart_form_data = {\n",
    "        'shapefile': ('south_america.geojson', fd1, 'application/geo+json'),\n",
    "        'subset': (None, 'time(\"2020-11-16T20:00:00.000Z\":\"2020-11-16T22:00:00.000Z\")')\n",
    "    }\n",
    "    # submit the form using a POST request and prepare to stream the result\n",
    "    if bearer_token:\n",
    "        shapefile_response = requests.post(shapefile_url, files=multipart_form_data, stream=True, auth=BearerToken(bearer_token))\n",
    "    else:\n",
    "        shapefile_response = requests.post(shapefile_url, files=multipart_form_data, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stream the result back and write it out to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_output_filepath = str(local_dir + 'shapefile_output.tif')\n",
    "with open(shapefile_output_filepath, 'wb') as fd:\n",
    "    for chunk in shapefile_response.iter_content(chunk_size=128):\n",
    "        fd.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the file as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file:\n",
    "shapefile_raster = rasterio.open(shapefile_output_filepath)\n",
    "\n",
    "# Read the grid values into numpy arrays\n",
    "red = shapefile_raster.read(3)\n",
    "green = shapefile_raster.read(2)\n",
    "blue = shapefile_raster.read(1)\n",
    "\n",
    "# Function to normalize the grid values\n",
    "def normalize(array):\n",
    "    \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\"\n",
    "    import numpy as np\n",
    "    np.seterr(divide='ignore', invalid='ignore') #ignore divide by 0 error\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    return ((array - array_min)/(array_max - array_min))\n",
    "\n",
    "# Normalize the bands\n",
    "redn = normalize(red)\n",
    "greenn = normalize(green)\n",
    "bluen = normalize(blue)\n",
    "\n",
    "# Create RGB natural color composite\n",
    "rgb = np.dstack((redn, greenn, bluen))\n",
    "\n",
    "# Let's see how our color composite looks like\n",
    "plt.imshow(rgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access reprojected data\n",
    "\n",
    "The Harmony API accepts reprojection requests with a given coordinate reference system using the `outputCrs` keyword. According to the Harmony API documentation, this keyword \"recognizes CRS types that can be inferred by gdal, including EPSG codes, Proj4 strings, and OGC URLs (http://www.opengis.net/def/crs/...) \". Two examples below demonstrate inputting an EPSG code and Proj4 string using the global test granule from previous examples. First, let's view the projection information of the granule in the native projection, using the variable subset example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_proj = gdal.Open(var_filepath, gdal.GA_ReadOnly)\n",
    "native_proj.GetProjection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request reprojection to EPSG 6933 (\"WGS 84 / NSIDC EASE-Grid 2.0 Global\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epsgConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'granuleid': granule_id,\n",
    "    'outputCrs': 'EPSG:6933',\n",
    "}\n",
    "\n",
    "epsg_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?&granuleid={granuleid}&outputCrs={outputCrs}'.format(**epsgConfig)\n",
    "print('Request URL', epsg_url)\n",
    "epsg_response = request.urlopen(epsg_url)\n",
    "epsg_results = epsg_response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reprojected output is downloaded to the Harmony outputs directory and the projection information can be viewed using GDAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_file_name = 'harmonyepsg.tif'\n",
    "epsg_filepath = str(local_dir+epsg_file_name)\n",
    "file_ = open(epsg_filepath, 'wb')\n",
    "file_.write(epsg_results)\n",
    "file_.close()\n",
    "\n",
    "# get projection information\n",
    "epsg = gdal.Open(epsg_filepath, gdal.GA_ReadOnly)\n",
    "epsg.GetProjection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output was reprojected to Cylindrical Equal Area as expected. We can do a visual check of this as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_raster = rasterio.open(epsg_filepath)\n",
    "epsg_band = epsg_raster.read(1)\n",
    "plt.imshow(epsg_band, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprojection can also be requested using a proj4 string. You must ensure that the proper URL encoding is included in the request so that proj4 string spaces and special characters are handled without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URL encode string using urllib parse package\n",
    "proj_string = '+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs' # proj4 of WGS 84 / NSIDC EASE-Grid 2.0 Global projection\n",
    "proj_encode = parse.quote(proj_string)\n",
    "\n",
    "projConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'granuleid': granule_id,\n",
    "    'outputCrs': proj_encode\n",
    "}\n",
    "\n",
    "proj_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?&granuleid={granuleid}&outputCrs={outputCrs}'.format(**projConfig)\n",
    "print('Request URL', proj_url)\n",
    "proj_response = request.urlopen(proj_url)\n",
    "proj_results = proj_response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reprojected output is downloaded to a directory with write permissions and the projection information can be viewed using GDAL. The projection is equivalent to the specified EPSG request above as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_file_name = 'harmonyproj4.tif'\n",
    "proj_filepath = str(local_dir+proj_file_name)\n",
    "file_ = open(proj_filepath, 'wb')\n",
    "file_.write(proj_results)\n",
    "file_.close()\n",
    "\n",
    "# get projection information\n",
    "proj = gdal.Open(proj_filepath, gdal.GA_ReadOnly)\n",
    "proj.GetProjection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Level 2 swath regridded data\n",
    "\n",
    "Moving outside of the `harmony/gdal` service, we will now request regridding from the `Swath Projector` service using the `C1233860183-EEDTEST`, or Harmony L2 swath example, collection provided in NetCDF format. \n",
    "\n",
    "\n",
    "The Harmony API accepts several query parameters related to regridding and interpolation in addition to the reprojection parameters above: \n",
    "\n",
    "`interpolation=<String>` - Both `near` and `bilinear` are valid options\n",
    "\n",
    "`scaleSize=x,y` - 2 comma separated numbers as floats\n",
    "\n",
    "`scaleExtent=xmin,ymin,xmax,ymax` - 4 comma separated numbers as floats\n",
    "\n",
    "`width=<Float>`  \n",
    "\n",
    "`height=<Float>` \n",
    "\n",
    "An error is returned if both `scaleSize` and `width`/`height` parameters are both provided (only one or the other can be used)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request reprojection to [Europe Lambert Conformal Conic](https://epsg.io/102014) with a new scale extent and nearest neighbor interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URL encode string using urllib parse package\n",
    "l2proj_string = '+proj=lcc +lat_1=43 +lat_2=62 +lat_0=30 +lon_0=10 +x_0=0 +y_0=0 +ellps=intl +units=m +no_defs'\n",
    "l2proj_encode = parse.quote(l2proj_string)\n",
    "\n",
    "\n",
    "regridConfig = {\n",
    "    'l2collection_id': 'C1233860183-EEDTEST',\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'granuleid': 'G1233860486-EEDTEST',\n",
    "    'outputCrs': l2proj_encode,\n",
    "    'interpolation': 'near',\n",
    "    'scaleExtent': '-7000000,1000000,8000000,8000000'\n",
    "}\n",
    "\n",
    "regrid_url = harmony_root+'/{l2collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?&granuleid={granuleid}&outputCrs={outputCrs}&interpolation={interpolation}&scaleExtent={scaleExtent}'.format(**regridConfig)\n",
    "print('Request URL', regrid_url)\n",
    "regrid_response = request.urlopen(regrid_url)\n",
    "regrid_results = regrid_response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reprojected and regridded output is downloaded to the Harmony outputs directory and we can inspect a variable to check for projection and grid dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regrid_file_name = 'regrid.nc'\n",
    "regrid_filepath = str(local_dir+regrid_file_name)\n",
    "file_ = open(regrid_filepath, 'wb')\n",
    "file_.write(regrid_results)\n",
    "file_.close()\n",
    "\n",
    "# Inspect dimensions of the blue_var:\n",
    "regrid_nc = Dataset(regrid_filepath)\n",
    "print(regrid_nc.variables.keys())\n",
    "blue_var = regrid_nc.variables['blue_var'] \n",
    "print(blue_var) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the x and y dimensions to confirm that the output matches the requested scale extent in meters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = regrid_nc.variables['x'] \n",
    "y = regrid_nc.variables['y'] \n",
    "print('min x', min(x), 'max x', max(x))\n",
    "print('min y', min(y), 'max y', max(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access multiple files from an asynchronous request\n",
    "\n",
    "By default, a request resulting in more than one file will be returned asynchronously via a Job URL. The initial request submission is automatically redirected to this URL, and output links are appended to the response as they complete. The following query should return three granules based on the following temporal range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asyncConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'time': '(\"2020-01-16T02:00:00.000Z\":\"2020-02-16T07:00:00.000Z\")',\n",
    "    'maxResults': 3\n",
    "}\n",
    "\n",
    "async_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?&subset=time{time}&maxResults={maxResults}'.format(**asyncConfig)\n",
    "print('Request URL', async_url)\n",
    "async_response = request.urlopen(async_url)\n",
    "async_results = async_response.read()\n",
    "async_json = json.loads(async_results)\n",
    "pprint.pprint(async_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The async response initially shows 0% progress. The initial request URL will automatically redirect to a job URL, which we can manually determine using the jobID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobConfig = {\n",
    "    'jobID': async_json['jobID']\n",
    "}\n",
    "\n",
    "job_url = harmony_root+'/jobs/{jobID}'.format(**jobConfig)\n",
    "print('Job URL', job_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `links` list in the job response will continue to be updated as outputs are produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_response = request.urlopen(job_url)\n",
    "job_results = job_response.read()\n",
    "job_json = json.loads(job_results)\n",
    "\n",
    "print('Job response:')\n",
    "print()\n",
    "pprint.pprint(job_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loop can be set up to query the job status and download outputs once the job is complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Continue loop while request is still processing\n",
    "while job_json['status'] == 'running' and job_json['progress'] < 100: \n",
    "    print('Job status is running. Progress is ', job_json['progress'], '%. Trying again.')\n",
    "    time.sleep(10)\n",
    "    loop_response = request.urlopen(job_url)\n",
    "    loop_results = loop_response.read()\n",
    "    job_json = json.loads(loop_results)\n",
    "    if job_json['status'] == 'running':\n",
    "        continue\n",
    "\n",
    "if job_json['status'] == 'successful' and job_json['progress'] == 100:\n",
    "    print('Job progress is 100%. Output links printed below:')\n",
    "    links = [link for link in job_json['links'] if link.get('rel', 'data') == 'data'] #list of data links from response\n",
    "    for i in range(len(links)):\n",
    "        link_dict = links[i] \n",
    "        print(link_dict['href'])\n",
    "        output_file_name = str(link_dict['title']+'.tif')\n",
    "        proj_filepath = str(local_dir+output_file_name)\n",
    "        file_ = open(proj_filepath, 'wb')\n",
    "        file_.write(proj_results)\n",
    "        file_.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previewing a small number of results\n",
    "\n",
    "By default, a request will return as many results as match the spatial and temporal query parameters, although this is subject to system limitations to prevent users from inadvertently overwhelming the system.  If a user wishes to further limit the number of results returned in order to preview a small number of results before requesting a larger transformation, they can simply supply a parameter called 'maxResults'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asyncConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'all',\n",
    "    'maxResults': '2'\n",
    "}\n",
    "\n",
    "async_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?&maxResults={maxResults}'.format(**asyncConfig)\n",
    "print('Request URL', async_url)\n",
    "async_response = request.urlopen(async_url)\n",
    "async_results = async_response.read()\n",
    "async_json = json.loads(async_results)\n",
    "pprint.pprint(async_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access WMS Map Image\n",
    "\n",
    "Harmony supports WMS requests, producing geo-registered map images, for all collections associated to a given Harmony transformation service. The following steps were adapted from the [ORNL DAAC help document](https://webmap.ornl.gov/ogc/help/wms_script_python.html) on interacting with a WMS service in Python, using the example harmony collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmsConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'service': 'WMS',\n",
    "    'version': '1.3.0',\n",
    "    'request': 'GetCapabilities',\n",
    "}\n",
    "\n",
    "wms_url = harmony_root+'/{collection_id}/wms?service={service}&version={version}&request={request}'.format(**wmsConfig)\n",
    "print('Request URL', wms_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the WMS service contents and titles of each variable layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if bearer_token:\n",
    "    wms_auth = Authentication(auth_delegate = BearerToken(bearer_token))\n",
    "    wms = WebMapService(wms_url, auth=wms_auth)\n",
    "else:\n",
    "    wms = WebMapService(wms_url)\n",
    "print(wms.identification.title)\n",
    "\n",
    "[op.name for op in wms.operations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = list(wms.contents)\n",
    "print ('Variable contents:')\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Variable titles:')\n",
    "[wms[contents[i]].title for i in range(len(contents))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Coherence layer and send request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh = contents[1] # Coherence layer\n",
    "\n",
    "# send the request\n",
    "img = wms.getmap(\n",
    "    layers=[coh],\n",
    "    version='1.3.0',\n",
    "    CRS='CRS:84',\n",
    "    styles=['default'],\n",
    "    bbox=(-180, -90, 180, 90), # Return full extent \n",
    "#    bbox=(-121.6,37.2,-120.57,38.0), # Example of a subset over California \n",
    "    granuleId='G1234088196-EEDTEST', # pick only one granule so the request won't time out\n",
    "    size=(600, 300),\n",
    "    format='image/png',\n",
    "    transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image file is downloaded to the Harmony outputs directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image in a local file\n",
    "img_name = '/coh.png'\n",
    "img_path = str(local_dir+img_name)\n",
    "out = open(img_path, 'wb')\n",
    "out.write(img.read())\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and plot the Coherence layer image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read png image file \n",
    "im = mpimg.imread(img_path) \n",
    "\n",
    "# show image \n",
    "plt.imshow(im) \n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Delivery of Results to a User's S3 Bucket\n",
    "\n",
    "Harmony result data can be delivered directly to a user's S3 bucket (at the root level or optionally to a specific folder). To allow Harmony to write to the bucket and to make the data readable to the user once it has been written requires the following:\n",
    "\n",
    "1. The bucket must be in the same AWS region as Harmony, `us-west-2`.\n",
    "2. The bucket must either disable access control lists (ACL) or set the ownership rules so that the bucket owner owns written objects (not the object writer). Otherwise the files written by Harmony will not be accessible to the user.\n",
    "3. A bucket policy must be attached to the bucket to allow Harmony to interact with it. The policy should enable the `s3:PutObject` and `s3:GetBucketLocation` actions.\n",
    "\n",
    "To facilitate step 3, Harmony provides an endpoint that can generate an appropriate bucket policy given a bucket name. The generated policy will only work for the Harmony environment from which it is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'my-bucket'\n",
    "parameters = { 'bucketPath': bucket_name }\n",
    "query_string = parse.urlencode( parameters ) \n",
    "bucket_policy_url = harmony_root+'/staging-bucket-policy?' + query_string\n",
    "\n",
    "policy_response = request.urlopen(bucket_policy_url)\n",
    "print(json.dumps(json.loads(policy_response.read().decode('utf-8')), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bucketPath` above can be a full S3 url, just a bucket name, or bucket name + key. All of the following are valid\n",
    "* `s3://my-bucket`\n",
    "* `s3://my-bucket/some/path`\n",
    "* `my-bucket`\n",
    "* `my-bucket/some/other/path`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0b323d74a2eccdefaacaf33c041ca03218ebb6c9aa84851ec587afd8a56d428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
